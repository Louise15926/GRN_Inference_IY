{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Gene Regulatory Network Prediction of Yeast Network\n",
    "# The task:\n",
    "# Predict which transcription factors affects genes (For now this is non-tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/Users/SamYang95/GRN_Inference_IY/scripts-notebooks\n"
    }
   ],
   "source": [
    "# # Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n",
    "# # ms-python.python added\n",
    "# import os\n",
    "# try:\n",
    "# \t# os.chdir(os.path.join(os.getcwd(), '..'))\n",
    "#     os.chdir(os.path.join(os.getcwd(), \"./scripts-notebooks\"))\n",
    "#     print(os.getcwd())\n",
    "# except Exception as e:\n",
    "# \tprint(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get expression data\n",
    "ko_df = pd.read_csv('../dataset/yeast_networks/expression/KO.txt', sep='\\t').set_index('Gene')\n",
    "nv_df = pd.read_csv('../dataset/yeast_networks/expression/NatVar.txt', sep='\\t').set_index('Gene')\n",
    "stress_df = pd.read_csv('../dataset/yeast_networks/expression/Stress.txt', sep='\\t').set_index('Name')\n",
    "\n",
    "# Get Transcription Factors\n",
    "ko_tf = pd.read_csv('../dataset/yeast_networks/expression/KO_TF_names.txt', sep='\\t', header=None)\n",
    "ko_tf.columns = ['TF']\n",
    "\n",
    "nv_tf = pd.read_csv('../dataset/yeast_networks/expression/NatVar_TF_names.txt', sep='\\t', header=None)\n",
    "nv_tf.columns = ['TF']\n",
    "\n",
    "stress_tf = pd.read_csv('../dataset/yeast_networks/expression/Stress_TF_names.txt', sep='\\t', header=None)\n",
    "stress_tf.columns = ['TF']\n",
    "\n",
    "# Note that there are different gene list for each df, so we will use ko as test for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ko_df.merge(nv_df, how='inner', left_index=True, right_index=True)\n",
    "df = df.merge(stress_df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "tf = ko_tf.merge(nv_tf, how='inner', left_on='TF', right_on='TF')\n",
    "tf = tf.merge(stress_tf, how='inner', left_on='TF', right_on='TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset: set which are the predictors (TF), and which are the targets\n",
    "from sklearn import model_selection\n",
    "def prep_dataset(target_gene, tf_list, exp_df):\n",
    "    '''\n",
    "    Prepares training set and test set for target gene\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        - tf_list: transcription factors, which will be the predictors (X)\n",
    "        \n",
    "    Returns:\n",
    "        - Training and Testing set to be used in model predictions\n",
    "        - label for predictors, so we can subset this later\n",
    "    '''\n",
    "    # Get y (target) and predictor matrix (X)\n",
    "    y = exp_df.loc[target_gene, :].values\n",
    "    X = exp_df.loc[tf_list, :]\n",
    "    \n",
    "    if target_gene in tf_list.values:\n",
    "        X = X.drop(index=target_gene)\n",
    "    \n",
    "    X_label = X.index # Predictor labels for X\n",
    "    X = X.values.transpose()\n",
    "    \n",
    "    # Split 80:20 for test and train\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def grn_lasso(target_gene, tf_list, exp_df):\n",
    "    '''\n",
    "    GRN inference method using lasso regression\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        - tf_list: transcription factors, which will be the predictors (X)\n",
    "        \n",
    "    Returns:\n",
    "        - Numpy array of type str, with list of non-zero weight predictors\n",
    "    '''\n",
    "    # Prep data\n",
    "    X_train, X_test, y_train, y_test, X_label = prep_dataset(target_gene, tf_list, exp_df)\n",
    "    \n",
    "    # Use Lasso regression\n",
    "    lasso_reg = LassoCV(alphas = [0.01, 0.1, 1, 10, 100], cv=5)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Get scores (R^2)\n",
    "    train_score = lasso_reg.score(X_train, y_train) # Note: R^2 not very good, maybe use other methods\n",
    "    test_score = lasso_reg.score(X_test, y_test)\n",
    "    \n",
    "    # Get weights of lasso, non zero weights are regulators\n",
    "    predictors = X_label\n",
    "    nonzero_filter = lasso_reg.coef_ != 0\n",
    "    nonzero_preds = predictors[nonzero_filter]\n",
    "    \n",
    "    return nonzero_preds.values\n",
    "\n",
    "def grn_regforest(target_gene, tf_list, exp_df):\n",
    "    '''\n",
    "    GRN inference method using regression forest. This method does not assume linearity of data.\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        - tf_list: transcription factors, which will be the predictors (X)\n",
    "        \n",
    "    Returns:\n",
    "        - Numpy array of type str, with list of non-zero weight predictors\n",
    "        \n",
    "    '''\n",
    "    # Prep data\n",
    "    X_train, X_test, y_train, y_test, X_label = prep_dataset(target_gene, tf_list, exp_df)\n",
    "    \n",
    "    # Use regerssion tree\n",
    "    forest_reg = RandomForestRegressor(n_estimators = 10, max_depth = 8, bootstrap = True, min_samples_leaf = 10, n_jobs=-1)\n",
    "    forest_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Get Scores (R^2)\n",
    "    train_score = forest_reg.score(X_train, y_train)\n",
    "    test_score = forest_reg.score(X_test, y_test)\n",
    "    \n",
    "    # Get feature importance\n",
    "    predictors = X_label\n",
    "    nonzero_filter = forest_reg.feature_importances_ != 0\n",
    "    nonzero_preds = predictors[nonzero_filter]\n",
    "    \n",
    "    return nonzero_preds.values\n",
    "\n",
    "\n",
    "\n",
    "# Read in an expression file, and predict GRN using a method\n",
    "def predict_grn(exp_df, tf_list, method, target_list=None, *args):\n",
    "    '''\n",
    "    Function that reads in expression level and predict its GRN using a specific method\n",
    "    \n",
    "    Args:\n",
    "        - exp_df: expression dataframe (already in pandas df format), index is gene names, columns are sample / treatments\n",
    "        - method: Method of inferring GRN (Example: grn_lasso)\n",
    "        - *args: additional arguments for method\n",
    "        - tf_list: transcription factors, which will be the predictors (X)\n",
    "        \n",
    "    Returns:\n",
    "        - Set of predicted edges with format (regulator(space)target)\n",
    "    '''\n",
    "    \n",
    "    pred_edges = set()\n",
    "\n",
    "    if target_list is None:\n",
    "        target_list = exp_df.index.values\n",
    "\n",
    "    # for target in exp_df.index.values:\n",
    "    for target in target_list:\n",
    "        # Get regulators for every target gene\n",
    "\n",
    "        pred_regs = method(target, tf_list, exp_df, *args)\n",
    "\n",
    "        # Add the predicted regulators -> target edge to the predicted edges\n",
    "        for reg in pred_regs:\n",
    "            pred_edges.add(f'{reg}->{target}')\n",
    "    \n",
    "    return pred_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only train on a subset of the target genes to speed up the tuning process\n",
    "num_target_genes = 10\n",
    "indices = np.random.randint(df.shape[0], size=num_target_genes)\n",
    "indices = [True if i in indices else False for i in range(df.shape[0])]\n",
    "target_list = df.loc[indices].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Time Training RegForest:  00:00:09\n"
    }
   ],
   "source": [
    "# Predict Edges\n",
    "import time\n",
    "\n",
    "time_0 = time.time()\n",
    "\n",
    "regforest_edges = predict_grn(df, tf.loc[:, 'TF'], grn_regforest, target_list=target_list)\n",
    "time_1 = time.time()\n",
    "print(\"Time Training RegForest: \", time.strftime(\"%H:%M:%S\", time.gmtime(time_1 - time_0)))\n",
    "\n",
    "# lasso_edges = predict_grn(df, tf.loc[:, 'TF'], grn_lasso)\n",
    "# time_2 = time.time()\n",
    "# print(\"Time Training Lasso: \", time.strftime(\"%H:%M:%S\", time.gmtime(time_2 - time_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Performance Metrics\n",
    "\n",
    "def iou_score(gold_df, pred_grn_edges, target_list=None):\n",
    "    '''\n",
    "    Function to score predicted grn vs gold standard based on intersection over union.\n",
    "\n",
    "    Score:\n",
    "    For starters, we will use the simple score of intersection / union\n",
    "    Intersection: Count of edges in both gold standard AND predicted grn\n",
    "    Union: Count of gold standard edges + predicted grn edges - Intersection\n",
    "\n",
    "    Intersection / Union is the score.\n",
    "\n",
    "    Args:\n",
    "        - gold_file: Path to gold standard file\n",
    "        - pred_grn_edges: set of predicted grn edges\n",
    "\n",
    "    Returns:\n",
    "        - IOU score\n",
    "    '''\n",
    "\n",
    "    # Set of gold standard edges\n",
    "    if target_list is not None:\n",
    "        gold_df = gold_df[gold_df['Target'].isin(target_list)]\n",
    "\n",
    "\n",
    "    gold_edge_set = set(gold_df.loc[:, 'Regulator'] + '->' + gold_df.loc[:, 'Target'])\n",
    "\n",
    "    gold_regulators = set(gold_df.loc[:, 'Regulator'])\n",
    "    pred_grn_edges = [edge for edge in pred_grn_edges if edge.split('->')[0] in gold_regulators]\n",
    "\n",
    "    # Get Intersection and Union\n",
    "    intersection = gold_edge_set.intersection(pred_grn_edges)\n",
    "    union = gold_edge_set.union(pred_grn_edges)\n",
    "\n",
    "    # Get score: Intersection / Union\n",
    "    iou_score = len(intersection) / len(union)\n",
    "    print(f'Union edges count: {len(union)}')\n",
    "    print(f'Intersection edges count: {len(intersection)}')\n",
    "        \n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ko_gold_df = pd.read_csv(\"../dataset/yeast_networks/gold/MacIsaac2.KO.txt\", sep = '\\t', header = None, names = ['Regulator', 'Target'])\n",
    "nv_gold_df = pd.read_csv(\"../dataset/yeast_networks/gold/MacIsaac2.NatVar.txt\", sep = '\\t', header = None, names = ['Regulator', 'Target'])\n",
    "stress_gold_df = pd.read_csv(\"../dataset/yeast_networks/gold/MacIsaac2.Stress.txt\", sep = '\\t', header = None, names = ['Regulator', 'Target'])\n",
    "\n",
    "gold_df = ko_gold_df.merge(nv_gold_df, how='outer', left_on=['Regulator', 'Target'], right_on=['Regulator', 'Target'])\n",
    "gold_df = gold_df.merge(stress_gold_df, how='outer', left_on=['Regulator', 'Target'], right_on=['Regulator', 'Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n                <audio  controls=\"controls\" autoplay=\"autoplay\">\n                    <source src=\"https://s3-us-west-2.amazonaws.com/1hbcf/Anna.mp3\" type=\"audio/mpeg\" />\n                    Your browser does not support the audio element.\n                </audio>\n              ",
      "text/plain": "<IPython.lib.display.Audio object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FinallyItIsDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Union edges count: 19\nIntersection edges count: 2\n"
    }
   ],
   "source": [
    "# lasso_score = iou_score(gold_df, lasso_edges)\n",
    "regforest_score = iou_score(gold_df, regforest_edges, target_list=target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f'KO Lasso score: {lasso_score}') # Much better than last time in try 1\n",
    "print(f'KO Regforest score: {regforest_score}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound alert after code is finished!\n",
    "from IPython.display import Audio, display\n",
    "def FinallyItIsDone():\n",
    "  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.mp3', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}