{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Regulatory Network Inference\n",
    "This is the notebook to process data and define functions before making a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCL expression data\n",
    "lcl_exp_path = '../dataset/LCL_networks/expression'\n",
    "lcl_geu = pd.read_csv(f'{lcl_exp_path}/Geuvadis.txt', sep = '\\t').set_index('Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prepare dataset function\n",
    "from sklearn import model_selection\n",
    "def prep_dataset(target_gene, exp_df):\n",
    "    '''\n",
    "    Prepares training set and test set for target gene\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        \n",
    "    Returns:\n",
    "        - Training and Testing set to be used in model predictions\n",
    "    '''\n",
    "    # Get y (target) and predictor matrix (X)\n",
    "    y = exp_df.loc[target_gene, :]\n",
    "    X = exp_df.drop(target_gene).transpose().values\n",
    "    \n",
    "    \n",
    "    # Split 80:20 for test and train\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def grn_lasso(target_gene, exp_df):\n",
    "    '''\n",
    "    GRN inference method using lasso regression\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        \n",
    "    Returns:\n",
    "        - Numpy array of type str, with list of non-zero weight predictors\n",
    "    '''\n",
    "    # Prep data\n",
    "    X_train, X_test, y_train, y_test = prep_dataset(target_gene, exp_df)\n",
    "    \n",
    "    # Use Lasso regression\n",
    "    lasso_reg = Lasso(alpha = 0.1)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Get scores (R^2)\n",
    "    train_score = lasso_reg.score(X_train, y_train) # Note: R^2 not very good, maybe use other methods\n",
    "    test_score = lasso_reg.score(X_test, y_test)\n",
    "    \n",
    "    # Get weights of lasso, non zero weights are regulators\n",
    "    predictors = exp_df.drop(target_gene).index\n",
    "    nonzero_filter = lasso_reg.coef_ != 0\n",
    "    nonzero_preds = predictors[nonzero_filter]\n",
    "    \n",
    "    \n",
    "    return nonzero_preds.values\n",
    "\n",
    "def grn_regforest(target_gene, exp_df):\n",
    "    '''\n",
    "    GRN inference method using regression forest. This method does not assume linearity of data.\n",
    "    \n",
    "    Args:\n",
    "        - target_gene: target gene for the iteration (y)\n",
    "        - exp_df: expression dataframe (already in pandas df format)\n",
    "        \n",
    "    Returns:\n",
    "        - Numpy array of type str, with list of non-zero weight predictors\n",
    "        \n",
    "    '''\n",
    "    # Prep data\n",
    "    X_train, X_test, y_train, y_test = prep_dataset(target_gene, exp_df)\n",
    "    \n",
    "    # Use regerssion tree\n",
    "    forest_reg = RandomForestRegressor(n_estimators = 10, max_depth = 8, bootstrap = True, min_samples_leaf = 10, n_jobs=-1)\n",
    "    forest_reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Get Scores (R^2)\n",
    "    train_score = forest_reg.score(X_train, y_train)\n",
    "    test_score = forest_reg.score(X_test, y_test)\n",
    "    \n",
    "    # Get feature importance\n",
    "    predictors = exp_df.drop(target_gene).index\n",
    "    nonzero_filter = forest_reg.feature_importances_ != 0\n",
    "    nonzero_preds = predictors[nonzero_filter]\n",
    "    \n",
    "    return nonzero_preds.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an expression file, and predict GRN using a method\n",
    "def predict_grn(exp_file, method, *args):\n",
    "    '''\n",
    "    Function that reads in expression level and predict its GRN using a specific method\n",
    "    \n",
    "    Args:\n",
    "        - exp_file: Path to expression file\n",
    "        - method: Method of inferring GRN (Example: grn_lasso)\n",
    "        - *args: additional arguments for method\n",
    "    \n",
    "    Returns:\n",
    "        - Set of predicted edges with format (regulator(space)target)\n",
    "    '''\n",
    "\n",
    "    exp_df = pd.read_csv(exp_file, sep = '\\t').set_index('Gene')\n",
    "\n",
    "    pred_edges = set()\n",
    "    \n",
    "    \n",
    "    for target in exp_df.index.values:\n",
    "        # Get regulators for every target gene\n",
    "        pred_regs = method(target, exp_df, *args)\n",
    "        \n",
    "        # Add the predicted regulators -> target edge to the predicted edges\n",
    "        for reg in pred_regs:\n",
    "            pred_edges.add(f'{reg}->{target}')\n",
    "    \n",
    "    return pred_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "\n",
    "def iou_score(gold_file, pred_grn_edges):\n",
    "    '''\n",
    "    Function to score predicted grn vs gold standard based on intersection over union.\n",
    "\n",
    "    Score:\n",
    "    For starters, we will use the simple score of intersection / union\n",
    "    Intersection: Count of edges in both gold standard AND predicted grn\n",
    "    Union: Count of gold standard edges + predicted grn edges - Intersection\n",
    "\n",
    "    Intersection / Union is the score.\n",
    "\n",
    "    Args:\n",
    "        - gold_file: Path to gold standard file\n",
    "        - pred_grn_edges: set of predicted grn edges\n",
    "\n",
    "    Returns:\n",
    "        - IOU score\n",
    "    '''\n",
    "\n",
    "    # Read in gold standard file\n",
    "    gold_df = pd.read_csv(gold_file, sep = '\\t', header = None, names = ['Regulator', 'Target']) \n",
    "\n",
    "    # Set of gold standard edges\n",
    "    gold_edge_set = set(gold_df.loc[:, 'Regulator'] + '->' + gold_df.loc[:, 'Target'])\n",
    "\n",
    "    # Get Intersection and Union\n",
    "    intersection = gold_edge_set.intersection(pred_grn_edges)\n",
    "    union = gold_edge_set.union(pred_grn_edges)\n",
    "\n",
    "    # Get score: Intersection / Union\n",
    "    iou_score = len(intersection) / len(union)\n",
    "    print(f'Union edges count: {len(union)}')\n",
    "    print(f'Intersection edges count: {len(intersection)}')\n",
    "    \n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union edges count: 34734\n",
      "Intersection edges count: 2\n",
      "Union edges count: 621345\n",
      "Intersection edges count: 230\n",
      "IOU Score, lasso: 5.758046870501526e-05\n",
      "IOU Score, regression random forest: 0.00037016472330186933\n"
     ]
    }
   ],
   "source": [
    "# Compare scores between methods vs gold standard\n",
    "lcl_gold = '../dataset/LCL_networks/gold/Cusanovich_gold.txt'\n",
    "lcl_geu_path = f'{lcl_exp_path}/Geuvadis.txt'\n",
    "\n",
    "# Predict using each methods\n",
    "lcl_lasso_pred = predict_grn(lcl_geu_path, grn_lasso)\n",
    "lcl_regforest_pred = predict_grn(lcl_geu_path, grn_regforest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union edges count: 34734\n",
      "Intersection edges count: 2\n",
      "Union edges count: 621345\n",
      "Intersection edges count: 230\n",
      "IOU Score, lasso: 5.758046870501526e-05\n",
      "IOU Score, regression random forest: 0.00037016472330186933\n"
     ]
    }
   ],
   "source": [
    "# Get iou scores\n",
    "lcl_lasso_iou = iou_score(lcl_gold, lcl_lasso_pred)\n",
    "lcl_regforest_iou = iou_score(lcl_gold, lcl_regforest_pred)\n",
    "\n",
    "print(f'IOU Score, lasso: {lcl_lasso_iou}')\n",
    "print(f'IOU Score, regression random forest: {lcl_regforest_iou}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
